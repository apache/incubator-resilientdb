# GraphQ-LLM Environment Configuration
# Copy this file to .env and fill in your values

# ============================================
# ResilientDB Configuration (Required)
# ============================================
RESILIENTDB_GRAPHQL_URL=http://localhost:5000/graphql
RESILIENTDB_API_KEY=

# ============================================
# ResLens Configuration (Optional - for Live Mode)
# ============================================
# Enable Live Mode for real-time stats accessible by LLM
RESLENS_API_URL=
RESLENS_API_KEY=
RESLENS_LIVE_MODE=false
RESLENS_POLL_INTERVAL=5000

# ============================================
# Nexus Configuration (Optional)
# ============================================
NEXUS_API_URL=
NEXUS_API_KEY=

# ============================================
# LLM Configuration (Required for AI features)
# ============================================
# LLM Provider: 'deepseek', 'openai', or 'anthropic'
LLM_PROVIDER=deepseek
LLM_API_KEY=
LLM_MODEL=deepseek-chat
# Enable Live Stats access for LLM (requires ResLens)
LLM_ENABLE_LIVE_STATS=false

# ============================================
# Embedding Configuration (Optional - Hugging Face)
# ============================================
# Hugging Face works without API key (public access, rate limited)
# Get free token from https://huggingface.co/settings/tokens for higher limits
HUGGINGFACE_API_KEY=

# ============================================
# MCP Server Configuration
# ============================================
MCP_SERVER_PORT=3001
MCP_SERVER_HOST=0.0.0.0

# ============================================
# Logging & Environment
# ============================================
LOG_LEVEL=info
NODE_ENV=development
